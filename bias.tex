\documentclass[11pt, oneside]{article}    

\usepackage{geometry}
\geometry{letterpaper}                          \usepackage{graphicx}               \usepackage{color}
\usepackage{xcolor}
\usepackage{amssymb}
\usepackage{hyperref}
\title{NIPS 2018 Competition proposal: Racial and Gender Bias in Face-based Attributes Analysis}
\author{Esube Bekele\thanks{The Leader organizer should be the first author of the proposal.} \and Timnit Gebru \and Joy Buolamwini \and Wallace Lawson \and Ian Goodfellow \\ \and
{\tt esube.bekele.ctr@nrl.navy.mil}\\
}
\date{\today}

\begin{document}
\maketitle

\subsection{Overview of the competition}
% Summarize the background, available data, methods, available baseline, potential impact.
% Background and impact review
Despite recent success of face recognition and facial attributes  analysis systems, research suggests existence of a wide range of unintentional biases toward a specific racial or gender group \cite{phillips2011other} \cite{klare2012face}. 
% Availbale data review
Recent study of effect of demographics on facial gender classification showed this bias on three commercially available gender classification systems \cite{buolamwini2018gender}. As part of eliciting these biases, a new dataset was collected that is balanced in gender and skin tone type called Pilot Parliaments Benchmark (PPB). We will primarily use this benchmark dataset as it is labeled with 
% Methods and available baseline for each track
The competition will have two separate tracks. In the first track, researchers will be generating samples from existing datasets to illustrate such racial and gender biases in existing facial attributes analysis commercial systems and methods. In the second track, we will provide imbalanced dataset for race and gender and researchers will submit solutions that learn the facial attribute while minimizing the gender and racial bias in the classification performance.

\subsection{Keywords}
Competition keywords, up to five, from generic to specific.

\subsection{Novelty}
% (Have you heard about similar competitions in the past? If yes, describe the key differences. O/w disregard)
%Indicate whether this is a completely new competition, a competition part of a series, eventually re-using old data.
To the best of our knowledge this will be the first time such competition that is targeted at eliciting racial and gender biases in face recognition and analysis systems and solving these biases using techniques other than simply balancing the training dataset. Balancing datasets for every demographic group and gender is usually impractical for commercial applications with consequential impact such as surveillance and law enforcement profiling.

\section{Competition description}

\subsection{Background and impact}

% Provide some background on the problem approached by the competition and fields of research involved. Describe the scope and indicate the anticipated impact of the competition prepared (economical, humanitarian, societal, etc.). Justify the relevance of the problem to the targeted NIPS community and indicate whether it is of interest to a large audience or limited to a small number of domain experts (estimate the number of participants). A good consequence for a competition is to learn something new by answering a scientific question or make a significant technical advance.
% Expanded Background
Psychologically, this is a well documented phenomenon called "own-race" or "other-race" bias that people recognize faces and face related attributes of their own race better than that of other races \cite{furl2002face}. These inherent biases affect manifests itself in face recognition and analysis systems primarily due to the unintentional imbalance in the datasets used to train such systems. The first breakdown of facial analysis systems performance by demographic groups\cite{phillips2011other} showed that these biases are

% Expanded impact

\subsection{Data}

If the competition uses an evaluation based on the analysis of data,
please provide detailed information of the available data and
their annotations, and, in case, what the data generation
procedure will be (in this case, it must be clear in the document
that the data will be ready prior to the official launch of the
competition). Please justify that: (1) you have access to large
enough datasets to make the competition interesting and draw
conclusive
 results; (2) the data can be made freely available;(3) the ground truth has been kept confidential.

\subsection{Tasks and application scenarios}

Describe the tasks of the competition and explain to which specific real-world scenario(s) they correspond to. If the competition does not lend itself
to real-world scenarios, provide a justification. Justify that the problem posed are scientifically or technically challenging but not impossible to
solve. If data are used, think of illustrating the same scientific problem using several datasets from various application domains.


\subsection{Metrics}

For quantitative evaluations, select a scoring metric and justify
that it effectively assesses the efficacy of solving the problem
at hand. It should be possible to evaluate the results
objectively. If no metrics are used, explain how the evaluation
will be carried out.

\subsection{Baselines and code available}

Specify what are (will be) the baselines for the competition, and
whether there is available code for participants (e.g., a starting
kit) and evaluation. Provide preliminary results, if available.

\subsection{Tutorial and documentation}

Provide a reference to a white paper you wrote describing the
problem and/or explain what tutorial material you will provide.


\section{Organizational aspects}
\subsection{Protocol}

Explain the procedure of the competition: what the participants will have to do, what will be submitted (results or code), and the evaluation procedure.
Will there be several phases? Will you use a competition platform with on-line submissions and a leader board? Indicate means of preventing cheating.
Provide your plan to organize beta tests of your protocol and/or platform.


\subsection{Rules}

Provide a list of special rules. 
For qualitative evaluations (e.g. demonstration competitions), select a committee and prepare guidelines for the committee.

\subsection{Schedule}

Provide a time line for competition preparation and for running the competition itself. Propose a reasonable schedule leaving enough time for the organizers
to prepare the event (a few months), enough time for the participants to develop their methods (e.g. 90 days), enough time for the organizers to review the entries, analyze and publish the results. 


\subsection{Competition promotion}

The plan that organizers have to promote participation in the competition (e.g., mailing lists in which the call will be distributed, invited talks, etc.).


\subsection{Organizing team}

Provide a short biography of all team members, stressing their competence for their assignments in the competition organization. Make sure to include: coordinators, data providers, platform administrators, baseline method providers, beta testers, and evaluators.


\section{Resources}
\subsection{Existing resources, including prizes}

Describe your resources (computers, support staff, equipment, sponsors, and available prizes).


%% The file named.bst is a bibliography style file for BibTeX 0.99c
\bibliographystyle{named}
%\bibliography{ijcai18}
\bibliography{egbib}

\end{document}
